{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f7753a-20a4-4a8e-9628-173554006def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "import tiktoken\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e60c8b-67fc-425b-8c18-ecb1aa804b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\") as f:\n",
    "    text = f.read()\n",
    "len(text)\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747fc6e0-1c49-41ff-801e-b7bff64d0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00383081-dab6-4b55-aa29-acfa14c6cb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asd'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctoi = {c: i for i, c in enumerate(chars)}\n",
    "itoc = {i: c for c, i in ctoi.items()}\n",
    "\n",
    "encode = lambda s: [ctoi.get(c, ctoi.get(\" \")) for c in s]\n",
    "decode = lambda l: \"\".join([itoc[i] for i in l])\n",
    "\n",
    "decode(encode(\"asd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59bc79b-fadd-42c4-b323-1de3c4c76a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.as_tensor(encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fe4113-e020-4bba-af75-1104f4b2e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2553d964-59c0-4d57-b082-cafff6858be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, block_size=8):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.block_size]\n",
    "        y = self.data[idx+1:idx+1+self.block_size]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017d1aa8-6f1e-492b-aa4f-dc703aad21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "vocab_size = len(itoc)\n",
    "\n",
    "train_dataset = SequenceDataset(train_data, block_size=block_size)\n",
    "test_dataset = SequenceDataset(test_data, block_size=block_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "sample = next(iter(train_dataset))\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3c4bb0-059c-4a60-8642-daf05bc7fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            ys_pred_proba =  self(idx)\n",
    "            ys_pred_proba = ys_pred_proba[:, -1, :]  # last time\n",
    "            ys_pred_proba = F.softmax(ys_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(ys_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0c6a7e67-9fc9-4eb1-8110-8e465ccf6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(pl.LightningModule):\n",
    "    def __init__(self, model, train_dataset, lr=1e-3, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "        Y_pred_proba = self.model(X)\n",
    "        loss = F.cross_entropy(\n",
    "            Y_pred_proba.reshape(-1, Y_pred_proba.shape[-1]),\n",
    "            Y.reshape(-1),\n",
    "        )\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1cd6a8a-f00d-43d6-8c6e-1136558c942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be0d24ee-9358-47c5-9877-f6d51327a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGK.uj,ZgX3&eLHtHHs$ypEfw,wVGT&ZGLGHBky!w$&;JFKKStFZCULUesBGtJdB&AK:k!'zVuidA\\nSNKn'j$mPrqpgzBJyP,B;OCUwg HAhRwn,UMdDHHUzOTrH$'3G:PY;?$DT\\nuufjOBlyBRwTNBLn&Zb\\n,E-wUiUR3:kES S?LMJ,m\\nY&EkQNbqY!qt;\\niqnPpcTg$IQiQDVYnmND,-:jGlxHhyQqXjfUmPpLFmfwFnR&e\\np3bqzOIVo3,Um\\nZC$KKSy;okRwT-3EfzsSHwFm:pm:3fhDryB'$v,LKSFjxCJdXidA.$lh fduzZAzwlmHrEjxSjrJtxt;A3xN?czYPy\\nMJbIzTNfA3,EzDaUiZy.MPRSRMlF&n,b&BH&BAlcqZ;Mh RLKEfLF3wpUa$JxmCtsGAnMhEdAD?ts;\\nPGD!c;zOyeV-l-PpPcEtIqlmYdBrI iMYLBYJCIcH!cIl,yPH f3$oagEpKveY3,CJt;d\\no!umPtQD;Y?.e\\nbJ,Uao,XEjxO.M.iMfOOsVldArIwzCMhFnWvI-SBejxkZgk.VoO?FczZanyBJ IjhPwrmEtGNc   ODOR;YON,lSOhKD.;Y?-lebAY:M'zYSDe:erDkcGTvR F khTuEfA$'I!,?m!;kE-3bjLKcSBH&SI.rquHxJbGMMPMOopA.;R\\n,GBpzYnW\\nCIQ-Oyg-xqOY;D,VNVLFkJctoE,UocomCQG!cZge\\naSZVrV\\nOD,CoHnBPpTuXLC'UQ$smUpb TJTrdWlELKSjxzr:\\npH\\nKTO\\nV;IVZglmkgCiP'znPE\\nJ$psOhDOlFzwoV\\naZLKRFeRw'$aMlKIKLKSlmNK\\nbGao'hPmHQK?NikH$H MXHQ\\n$lmko\\nr-PpKKaL\\nr!cks?naQ?NwpKUbcS;sdoS:i\\nKrcWDafDm-vMDsKYF JOIduYNiqBdkydkULMQzAtyeLGKv\\nacS;JyJU$kEHJ?O;-U&ZqS;'.fAD3,zDwCUvIl\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "decode(model.generate(idx, max_new_tokens=1000)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eab2316-df19-4e80-a52f-92fbc137bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cebdc98-2849-48b7-8e97-37f08d0eacef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/core/module.py:423: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.7994, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b138c206-553a-431f-8372-19634d19b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | BigramModel | 4.2 K \n",
      "--------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.011206626892089844,
       "initial": 0,
       "n": 0,
       "ncols": 58,
       "nrows": 23,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8d107059e249648e54d3c866bb6aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85faa1b-ad4a-4fdc-9bec-bb39262eacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db3d26-b92f-4d4a-9af6-44d9a08b2cef",
   "metadata": {},
   "source": [
    "Now we want some additions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d260909-dec4-40f6-8904-b454684b1cc2",
   "metadata": {},
   "source": [
    "Instead of predicting just based on the previous token, we want to **predict based on** a **context** of past tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13090a-8bf7-4465-91e6-da82c54e256c",
   "metadata": {},
   "source": [
    "One way to achive this we do a little trick: instead of predicting based on the previous token embedding, we will use the **average** of the past token embeddings. There we have a kind of context!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0ad01-794f-43fa-ad06-587853c184a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "batch_size = 6\n",
    "context_size = 8\n",
    "embedding_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0dcad-bd32-47aa-9e32-37d44a6a572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f28d3497d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.rand(batch_size, context_size, embedding_dim)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689da3a4-55af-409e-aa9f-3a6a4636feea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f28d068de50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = torch.tril(torch.ones(context_size, context_size))\n",
    "weights /= weights.sum(dim=1)[:, None]\n",
    "plt.imshow(weights, cmap=\"gray\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2d214-4b72-49b5-8146-0b0a2464fe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f28d062f850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = weights[None, :] @ x\n",
    "plt.imshow(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6966bb3-e165-42ab-99a9-0aa8669e9d8a",
   "metadata": {},
   "source": [
    "Now every token is transformed into its context until now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0c23092-673e-4b0a-b31d-73e8354985a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.token_embedder = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear_head = torch.nn.Linear(embedding_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        token_embeddings = self.token_embedder(idx)\n",
    "        x = token_embeddings\n",
    "        \n",
    "        w = torch.tril(torch.ones(x.shape[1], x.shape[1]))\n",
    "        w /= w.sum(dim=1)[:, None]\n",
    "        x = w[None, ...] @ x\n",
    "\n",
    "        y_pred_proba = self.linear_head(x)\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            Y_pred_proba =  self(idx)\n",
    "            Y_pred_proba = Y_pred_proba[:, -1, :]  # last time\n",
    "            Y_pred_proba = F.softmax(Y_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(Y_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dd16edc-a63a-48ed-8914-75244d8cec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba66f10-75bf-4e31-be4e-fb39e8b3d48d",
   "metadata": {},
   "source": [
    "to have a context for all the past tokens related to it, and no information from the future tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e971cf24-2378-4075-80cc-a02e55b82a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/core/module.py:423: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.1730, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d3079632-7666-4be3-a39c-1890fc32a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | BigramModel | 8.5 K \n",
      "--------------------------------------\n",
      "8.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.5 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.01120305061340332,
       "initial": 0,
       "n": 0,
       "ncols": 56,
       "nrows": 21,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538a8d7cc3ab4527bd720297492f2e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1024274b-0137-43a6-83ac-033b803609c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "USESLTEO::rM hOnh:,W p\n",
      "Au  xNnfe F\n",
      "ndEy\n",
      "\n",
      " a\n",
      "Ootav \n",
      "hhhMloIoM\n",
      "sane\n",
      "  rpeMGvl romeo dvy yes'ohlliamwnecoorue' uairtf dioa  Lwagt a\n",
      "attl shprmocy,rp bo?c o  do,tAthieaoeo sifsetame!farlagursipeer\n",
      "seaa  !e Bbc;i reult'utr ogvr tym tloh reonobsmasRmhtS,yr  hJkih H ahnwut mWeituht obh  nobns  sBacuRC  yaasl  y\n",
      " m atfnyl aru tem tzoide,uc tpreraehne!    rsnhutchamailg,oorGhy \n",
      "tt\n",
      "oic?eohehlietWh\n",
      "ehmmsh ugm-edaat rd ht ykleImonabeionsw,: ta  di!ad er llWpehVsTsIeep uetieutt  sgs eehcf prCt'i s\n",
      "ao tead u \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6534a76-1485-4f2c-887f-004ce7129130",
   "metadata": {},
   "source": [
    "## Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc044ea-7e79-4642-9374-10730bb1d85d",
   "metadata": {},
   "source": [
    "Attention gives us weighted average of previous embeddings for each token (context), but the weights are based on previous data itself. This is not common!\n",
    "\n",
    "This not only gives a token embedding valuable context, but...\n",
    "\n",
    "It is already a non-linearity!\n",
    "\n",
    "Here is how it works:\n",
    "\n",
    "$x := embeddings$\n",
    "\n",
    "$k = key(x)$\n",
    "\n",
    "$q = query(x)$\n",
    "\n",
    "$v = value(x)$\n",
    "\n",
    "$w = q @ k^T$\n",
    "\n",
    "$w = norm(w)$\n",
    "\n",
    "$out = w @ v$\n",
    "\n",
    "The weights are not given as a the output of some linear layer. They are a linear combination of data x data. It is as non-linear as $cxy$ in the following polynomial:\n",
    "\n",
    "$p(x,y) = ax + by + cxy + d$ (2nd degree polynomial!)\n",
    "\n",
    "In fact, when we apply w to v it is another non-linear degree.\n",
    "\n",
    "That is exactly why weights have to be normalized, because they they end up with magnitude of data**2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "607e6299-0f40-4ade-9ff4-dfcf8b42a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedder = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.linear_head = torch.nn.Linear(head_size, vocab_size)\n",
    "        # self.register_buffer(\"tril\", torch.tril(block_size, block_size))\n",
    "        self.key = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.query = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.value = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        token_embeddings = self.token_embedder(idx)\n",
    "        x = token_embeddings\n",
    "        \n",
    "        # self-attention mechanism start\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        w = q @ k.transpose(-1, -2)\n",
    "        w = w / k.shape[-1] ** 0.5\n",
    "                \n",
    "        tril = torch.tril(torch.ones(w.shape[-1], w.shape[-1]))\n",
    "        w = w.masked_fill(tril==0, -torch.inf)\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        \n",
    "        v = self.value(x)\n",
    "        x = w @ v\n",
    "        # self-attention mechanism end\n",
    "        \n",
    "        y_pred_proba = self.linear_head(x)\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            Y_pred_proba =  self(idx)\n",
    "            Y_pred_proba = Y_pred_proba[:, -1, :]  # last time\n",
    "            Y_pred_proba = F.softmax(Y_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(Y_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3d0a94aa-5ece-4f6e-8f5b-715c22030c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "embedding_size = 32\n",
    "block_size = 8\n",
    "model = BigramModel(vocab_size, embedding_size, head_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66a54a0b-89fe-4682-aaaa-41440ecccdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1750, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6e719-5f7e-48de-8a9e-08a2d93323db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db90648-3d5d-423f-ba38-1f1aaae5fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OHARK:\n",
      "BA:\n",
      "\n",
      "WWhaine wowancy ver curakCKI d wd:\n",
      "Ty pnceam s t asy hisstofer he nd nes st, lr s , uriho athosisu\n",
      "ULile mr re w lousEthme wkinls, ncos\n",
      "C t amor,\n",
      "hy hiree ary gd menof d, cotod hithe gor, torthenlrie fofpad arer, or, le awatifee, f havisthy Ie d l hin aldessur hicounooacrrro nmad fl yormdse y, fe atrychy n hey he\n",
      "S Iren hiicide h thit?Id co acatidif anong\n",
      "Mae tsp st\n",
      ":ot r sothe uof tp ond le f thagwed, wlr grmis wm, himed! ashos lsunure, m thad me? wimastte nds su beaniminthor tily! \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41f5b1-132c-434b-9843-cadf5dacc74f",
   "metadata": {},
   "source": [
    "Now we can add position information as input to the model, so that we get position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33628141-b11a-4242-8e9d-7270b43bf02b",
   "metadata": {},
   "source": [
    "Not better results now. Another important thing in transformer paper is the position embedding. That is: to treat position as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ae0ece2-4a89-4e19-871a-dae2c3ba257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.key = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.query = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.value = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        tril = torch.tril(torch.ones(block_size, block_size))\n",
    "        self.register_buffer(\"tril\", tril)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        steps = x.shape[1]\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        w = self.get_weights(q, k, steps)\n",
    "        v = self.value(x)\n",
    "        v =  w @ v\n",
    "        return v\n",
    "    \n",
    "    def get_weights(self, q, k, steps):\n",
    "        w = q @ k.transpose(-1, -2)\n",
    "        w = w / k.shape[-1] ** 0.5\n",
    "        tril = self.tril[:steps, :steps]\n",
    "        w = w.masked_fill(tril==0, -torch.inf)\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        return w\n",
    "\n",
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedder = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.position_embedder = torch.nn.Embedding(block_size, embedding_size)\n",
    "        self.attention_head = AttentionHead(embedding_size, head_size, block_size)\n",
    "        self.linear_head = torch.nn.Linear(head_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        token_embeddings = self.token_embedder(idx)\n",
    "        \n",
    "        position = torch.arange(idx.shape[1])\n",
    "        position_embeddings = self.position_embedder(position)\n",
    "\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.attention_head(x)\n",
    "        y = self.linear_head(x)\n",
    "        return y\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        block_size = self.position_embedder.weight.shape[0]\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            Y_pred_proba =  self(idx_cond)\n",
    "            Y_pred_proba = Y_pred_proba[:, -1, :]  # last time\n",
    "            Y_pred_proba = F.softmax(Y_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(Y_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec1b2429-78d3-4a5d-83b8-8772aedc5156",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "embedding_size = 32\n",
    "block_size = 8\n",
    "model = BigramModel(vocab_size, embedding_size, head_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc7c8e66-a022-444b-889a-01f3c258fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/core/module.py:423: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.3378, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4fd6027e-247a-4af7-988b-d7994f5f3946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | BigramModel | 5.0 K \n",
      "--------------------------------------\n",
      "5.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000, log_every_n_steps=100)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6ddb7908-aad5-482b-858a-e17be23115ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mut re mme othand iaithearnty khe\n",
      "S:\n",
      "Fagouwr, thin mresle t's ogs:\n",
      "The ads gto dt mome thre whart ceart tive anganll ngede ikes:\n",
      "QUEELO:\n",
      "Thealt gt I, lllereeve thod wio yono ng ble.\n",
      "\n",
      "The see:\n",
      "So''s, hiuncicikinmisind, hancoterbu chat sundod fevere;\n",
      "Pll be\n",
      "\n",
      "IFriky he for tis ghe ks lioncro bly,\n",
      "CLY 'ce gpe kpopoerde ifit olain homf wa sury fon undo, ss mod waloto Thingo?\n",
      "Iertridsie ls.\n",
      "\n",
      "Jo ls scoourd anucat tlonour ba?\n",
      "-':\n",
      "Nor tt cive b.\n",
      "\n",
      "OR:\n",
      "Hougn acron gen my ty heexo rtorn kro maca the ilasndr\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "797e712d-3d72-4757-8785-33c69a6561e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.key = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.query = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.value = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        tril = torch.tril(torch.ones(block_size, block_size))\n",
    "        self.register_buffer(\"tril\", tril)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        steps = x.shape[1]\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        w = self.get_weights(q, k, steps)\n",
    "        v = self.value(x)\n",
    "        v =  w @ v\n",
    "        return v\n",
    "    \n",
    "    def get_weights(self, q, k, steps):\n",
    "        w = q @ k.transpose(-1, -2)\n",
    "        w = w / k.shape[-1] ** 0.5\n",
    "        tril = self.tril[:steps, :steps]\n",
    "        w = w.masked_fill(tril==0, -torch.inf)\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        return w\n",
    "    \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, head_size, n_heads, block_size):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([\n",
    "            AttentionHead(embedding_size, head_size, block_size)\n",
    "            for _ in range(n_heads)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, head_size, n_heads, block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedder = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.position_embedder = torch.nn.Embedding(block_size, embedding_size)\n",
    "        self.multi_head_attention = MultiHeadAttention(embedding_size, head_size, n_heads, block_size)\n",
    "        self.linear_head = torch.nn.Linear(head_size*n_heads, vocab_size)\n",
    "        self.register_buffer(\"position\", torch.arange(block_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        token_embeddings = self.token_embedder(x)\n",
    "        position_embeddings = self.position_embedder(self.position[:x.shape[1]])\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.multi_head_attention(x)\n",
    "        y = self.linear_head(x)\n",
    "        return y\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        block_size = self.position_embedder.weight.shape[0]\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            Y_pred_proba =  self(idx_cond)\n",
    "            Y_pred_proba = Y_pred_proba[:, -1, :]  # last time\n",
    "            Y_pred_proba = F.softmax(Y_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(Y_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d7c0e6df-5bcd-4d6d-8c56-3d4380e89c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "block_size = 8\n",
    "n_heads = 4\n",
    "head_size = embedding_size // n_heads\n",
    "model = BigramModel(vocab_size, embedding_size, head_size, n_heads, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "88825c9f-7f2d-4846-b8c7-be0d3684c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1169, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77aed2f4-65ec-49b4-b829-3a3eefbf3c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | BigramModel | 7.6 K \n",
      "--------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n",
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000, log_every_n_steps=100)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "720e145e-ab71-44a3-b648-81db28aa9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETO'd parrs grat cow\n",
      "BOLI ry what! evey,\n",
      "To onge!\n",
      "Ror' hulland hous,,\n",
      "Haruert.\n",
      "\n",
      "BRB\n",
      "POLAMINCESS:\n",
      "row he,\n",
      "Joncu,\n",
      "Hir\n",
      "INoque of whist Ha now't now ble:\n",
      "E Erhat.\n",
      "\n",
      "No? Yourichey suren your coourngy stherveise gackishe thatdes,\n",
      "Thin.\n",
      "\n",
      "CWAUFEMIS: wi wilhtew'd wead uspe Singon.\n",
      "Whantee net so, men aprt reve ige flis os pored; bent sot heich herir'dd I wha lorr st a dessevernd\n",
      "Andy:\n",
      "That winceng enk whe dos ares micarel.\n",
      "\n",
      "LANRY Pardy: gardescersome ane;\n",
      "youc I:\n",
      "rne cowea,\n",
      "My seer fand rour fighs I your \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e42e0f0-57a6-4c4f-ad66-4d12f78195b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, head_size, block_size, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.key = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.query = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.value = torch.nn.Linear(embedding_size, head_size, bias=False)\n",
    "        tril = torch.tril(torch.ones(block_size, block_size))\n",
    "        self.register_buffer(\"tril\", tril)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        steps = x.shape[1]\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        w = self.get_weights(q, k, steps)\n",
    "        w = self.dropout(w)\n",
    "        v = self.value(x)\n",
    "        v =  w @ v\n",
    "        return v\n",
    "    \n",
    "    def get_weights(self, q, k, steps):\n",
    "        w = q @ k.transpose(-1, -2)\n",
    "        w = w / k.shape[-1] ** 0.5\n",
    "        tril = self.tril[:steps, :steps]\n",
    "        w = w.masked_fill(tril==0, -torch.inf)\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        return w\n",
    "    \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, head_size, n_heads, block_size, dropout=0):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([\n",
    "            AttentionHead(embedding_size, head_size, block_size, dropout)\n",
    "            for _ in range(n_heads)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92d46266-d86f-420b-a2ef-9095c6a500f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes=(), act=torch.nn.ReLU, last_act=None, dropout=0.):\n",
    "        super().__init__()\n",
    "        if last_act is None:\n",
    "            last_act = torch.nn.Identity\n",
    "        sizes = [input_size, *hidden_sizes, output_size]\n",
    "        layers = []\n",
    "        for size_in, size_out in zip(sizes[:-1], sizes[1:]):\n",
    "            layers.append(torch.nn.Linear(size_in, size_out))\n",
    "            layers.append(act() if size_out != output_size else last_act())\n",
    "        self.net = torch.nn.Sequential(*layers[:-1])  # Exclude the last activation\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e5aff46-26f6-430f-9e07-e5485a92d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, n_heads, block_size, ff_hidden_size, dropout=0.):\n",
    "        super().__init__()\n",
    "        assert embedding_size % n_heads == 0\n",
    "        head_size = embedding_size // n_heads\n",
    "        self.self_attention = MultiHeadAttention(embedding_size, head_size, n_heads, block_size)\n",
    "        self.mlp = MLP(embedding_size, embedding_size, hidden_sizes=[ff_hidden_size], dropout=dropout)\n",
    "        self.norm_0 = torch.nn.LayerNorm(embedding_size)\n",
    "        self.norm_1 = torch.nn.LayerNorm(embedding_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # adding residuals, layer norm and droppout\n",
    "        x = x + self.self_attention(self.norm_0(x))\n",
    "        x = x + self.mlp(self.norm_1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7f3e75ee-afeb-4c76-b787-e97c72921a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, n_heads, n_transformer_blocks, block_size, ff_hidden_size=4, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.token_embedder = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.position_embedder = torch.nn.Embedding(block_size, embedding_size)\n",
    "        self.blocks = torch.nn.Sequential(*[\n",
    "            TransformerBlock(embedding_size, n_heads, block_size, ff_hidden_size, dropout=dropout)\n",
    "            for _ in range(n_transformer_blocks)\n",
    "        ])\n",
    "        self.norm = torch.nn.LayerNorm(embedding_size)\n",
    "        self.linear_head = torch.nn.Linear(embedding_size, vocab_size)\n",
    "        self.register_buffer(\"position\", torch.arange(block_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        token_embeddings = self.token_embedder(x)\n",
    "        position_embeddings = self.position_embedder(self.position[:x.shape[1]])\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        y = self.linear_head(x)\n",
    "        return y\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        block_size = self.position_embedder.weight.shape[0]\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            Y_pred_proba =  self(idx_cond)\n",
    "            Y_pred_proba = Y_pred_proba[:, -1, :]  # last time\n",
    "            Y_pred_proba = F.softmax(Y_pred_proba, dim=-1)\n",
    "            idx_next = torch.multinomial(Y_pred_proba, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b18cf1-bd7f-4faf-ba2c-40fed3919adb",
   "metadata": {},
   "source": [
    "embedding_size = 32\n",
    "block_size = 8\n",
    "n_heads = 4\n",
    "head_size = embedding_size // n_heads\n",
    "n_transformer_blocks = 4\n",
    "ff_hidden_size = 4\n",
    "model = BigramModel(vocab_size, embedding_size, n_heads, n_transformer_blocks, block_size, ff_hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2235e96b-ec06-4942-be56-d417805fe5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/core/module.py:423: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.6275, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c27bc09d-4262-403b-a106-a39bfa125892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | BigramModel | 17.9 K\n",
      "--------------------------------------\n",
      "17.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.9 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n",
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.010879755020141602,
       "initial": 0,
       "n": 0,
       "ncols": 143,
       "nrows": 37,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff5a626ed7f4790b7efc91f7e37d9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "trainer = pl.Trainer(max_epochs=10, limit_train_batches=1000, log_every_n_steps=100)\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c3099-3c80-4c71-9c31-481eafee6b2f",
   "metadata": {},
   "source": [
    "batch_norm: normalize (ONLY) the columns of each batch for mean=0 and std=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0a55a892-c809-4759-894f-c174c0527863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Arably whe broldove hou'lld heor, hat.\n",
      "\n",
      "Plavave have no oathers but hor e my nat jcme llens aver bam sis't; wil slllok,\n",
      "I:\n",
      "Men sish idees thou wold neand helqly.\n",
      "WAUnd stleenor-':\n",
      "EN with lllaks', Sall vere thout high\n",
      "Mis der theat strotmerr\n",
      "No wreight wre, I noth'd of with hou ghoaghat uthe mex! he gind trean.\n",
      "Fror whow?\n",
      "Wgh founch I this me-pcesss ineste whild:\n",
      "Provioul poour r fourdmt I crout goughe or therd:\n",
      "Gour lad?\n",
      "Se weld haste ssemullfor KINothth conttler his twie ll hooverk; you.\n",
      "MUKI\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb8762ec-7dc2-4a28-8615-2919b3731f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = Path(\"~/jrn\").expanduser()\n",
    "text_paths = list(text_dir.glob(\"*.md\"))\n",
    "\n",
    "text = []\n",
    "for path in text_dir.glob(\"*.md\"):\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            text.append(f.read())\n",
    "    except:\n",
    "        pass\n",
    "text = \"\\n\\n\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d51f028-f152-4a69-83c1-4b2c7a5f25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "tokens_tiktoken = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1df663c7-eea2-4e00-b4be-805c81d16701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "unique_tokens = sorted(set(tokens_tiktoken))\n",
    "n_vocab = len(unique_tokens)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_tokens)\n",
    "tokens = label_encoder.transform(tokens_tiktoken)\n",
    "tokens_tiktoken_decoded = label_encoder.inverse_transform(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d33400e8-a220-4952-a907-61ad041a6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.as_tensor(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2f83ec3-f1fe-4114-9fd3-e08b92d2b15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2773350736814395"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0f5f3db-5d84-4eaa-a09c-e345d29e7d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100277"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a74e7477-e95e-49f1-9ca6-0d4a0c79468f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5809"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({*tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "75ab6339-64af-4f8d-bdfa-ca78863871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "\n",
    "train_dataset = SequenceDataset(train_data, block_size=block_size)\n",
    "test_dataset = SequenceDataset(test_data, block_size=block_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "sample = next(iter(train_dataset))\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "48ede981-bea0-44e0-a3a0-eb43e398133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_heads = 8\n",
    "head_size = 64\n",
    "embedding_size = head_size * n_heads\n",
    "block_size = 32\n",
    "vocab_size = len({*tokens})\n",
    "dropout = 0.4\n",
    "# vocab_size = tokenizer.n_vocab\n",
    "n_transformer_blocks = 4\n",
    "ff_hidden_size = 4\n",
    "model = BigramModel(vocab_size, embedding_size, n_heads, n_transformer_blocks, block_size, ff_hidden_size, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d0869116-7258-4bef-a474-090c9694d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcosrdac/.conda/lib/python3.9/site-packages/pytorch_lightning/core/module.py:423: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(8.8694, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "pl_model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8546747d-fcc2-484d-9e8f-802a06ad59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(s):\n",
    "    return tokenizer.decode(label_encoder.inverse_transform(s.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de0baf-fefc-49bf-941c-a9e381c62a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, max_new_tokens=20)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d3186-79ac-4362-ac25-0eac1d1b12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = LanguageModel(model, train_dataset=train_dataset, batch_size=32)\n",
    "trainer = pl.Trainer(max_epochs=10, log_every_n_steps=100, accelerator=\"xla\")\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8b628cce-c70f-4767-a11d-cfd1c0acb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daefbab1-c18b-4111-a180-de5f652923ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(model_eval.generate(idx, max_new_tokens=100)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c2c3bd53-af9c-4f0f-a92f-a4d5e62e3031",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Meu nome \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fdd0ee4c-3f38-4465-8746-ec545ce342fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.as_tensor(encoder.transform(tokenizer.encode(s))[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578c8ac-58f0-4cf5-97ef-8afb75d8a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decode(model_eval.generate(t, max_new_tokens=100)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5aa9a-9655-4b54-9ec2-b23c58542a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head, is_causal=False, bias=True, dropout=0.):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0\n",
    "        self.n_embd = n_embd\n",
    "        self.n_head = n_head\n",
    "        self.head_size = n_embd // n_head\n",
    "        self.is_causal = is_causal\n",
    "        self.qkv = torch.nn.Linear(n_embd, 3*n_embd, bias=bias)\n",
    "        self.projection = torch.nn.Linear(n_embd, n_embd, bias=bias)\n",
    "        # regularization\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v  = torch.split(qkv, self.n_embd, dim=-1)        \n",
    "        # unpack heads to 2nd dim\n",
    "        k = k.view(*x.shape[:2], self.n_head, self.head_size).transpose(1, 2)\n",
    "        q = q.view(*x.shape[:2], self.n_head, self.head_size).transpose(1, 2)\n",
    "        v = v.view(*x.shape[:2], self.n_head, self.head_size).transpose(1, 2)\n",
    "        \n",
    "        dropout = self.dropout if self.training else 0.\n",
    "        y = F.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=dropout, is_causal=self.is_causal)        \n",
    "        y = y.transpose(1, 2).contiguous().view(x.shape)\n",
    "        y = self.projection(y)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
